{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB4wwgtOLIDL"
      },
      "source": [
        "# Lecture 18. PyTorch Classification\n",
        "\n",
        "> Eunmi Kim    \n",
        " 계산과학 프로그래밍 및 실습\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecPGj-1BLGKN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oacrxO8GzmF"
      },
      "source": [
        "# device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('Current device is %s.'% device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fOvverICObY"
      },
      "source": [
        "## 1. Data\n",
        "\n",
        "MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxGzI_MACJVB"
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n",
        "                             transform=transforms.ToTensor())\n",
        "\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True,\n",
        "                            transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of training data: ', len(mnist_train))\n",
        "print('number of test data: ', len(mnist_test))"
      ],
      "metadata": {
        "id": "FrP9KnuVu0SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZtbB2vqYcNy"
      },
      "source": [
        "mnist_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytV5U4WjSQ2R"
      },
      "source": [
        "# 데이터 확인\n",
        "image, label = mnist_train[0]\n",
        "\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image)"
      ],
      "metadata": {
        "id": "PbJJqHxrwNlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTUi-FUiSliJ"
      },
      "source": [
        "plt.imshow(image.view(28, 28), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWsE6MxtS-z6"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8XeaIsmG5jm"
      },
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMdb_xZqHFHK"
      },
      "source": [
        "# dataset loader (for mini-batch training)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                          batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZHJH9pOl8PW"
      },
      "source": [
        "## 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "one-u44fHqic"
      },
      "source": [
        "# nn layers\n",
        "linear1 = nn.Linear(784, 512, bias=True)\n",
        "linear2 = nn.Linear(512, 256)\n",
        "linear3 = nn.Linear(256, 10)\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# model\n",
        "model = nn.Sequential(linear1, relu,\n",
        "                      linear2, relu,\n",
        "                      linear3).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH-jSYC2ZDMi"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKHcPGhrl_Fj"
      },
      "source": [
        "## 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am4BhGOAVQbS"
      },
      "source": [
        "total_batch = len(train_loader)\n",
        "print(total_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, Y in test_loader:\n",
        "    print(X.shape, Y.shape, sep='\\n')\n",
        "    break"
      ],
      "metadata": {
        "id": "bEmuC8ns0zb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGgK7-QaIw31"
      },
      "source": [
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_loss = correct = 0\n",
        "\n",
        "    for X, Y in train_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        Y_pred = model.forward(X)\n",
        "        loss = criterion(Y_pred, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_loss += loss / total_batch\n",
        "\n",
        "        correct_prediction = torch.argmax(Y_pred, 1) == Y\n",
        "        correct += correct_prediction.sum()\n",
        "\n",
        "    acc = (100*correct/len(train_loader.dataset))\n",
        "    train_acc_list.append(acc.item())\n",
        "    train_loss_list.append(avg_loss.item())\n",
        "    print(\"Epoch %2d: loss %.4f   accuracy %.2f\" % (epoch+1, avg_loss, acc))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY3HMAMHXDe7"
      },
      "source": [
        "# plot loss\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(1, epochs+1), train_loss_list)\n",
        "plt.title('Training Loss')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(1, epochs+1), train_acc_list)\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7qk3f4taWpw"
      },
      "source": [
        "## Model 평가"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    # Test the model using test sets\n",
        "    for X, Y in test_loader:\n",
        "        X_test = X.view(-1, 28 * 28).to(device)\n",
        "        Y_test = Y.to(device)\n",
        "\n",
        "        prediction = model.forward(X_test)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "        correct += correct_prediction.sum()\n",
        "\n",
        "    accuracy = 100*correct/len(test_loader.dataset)\n",
        "    print('Test set Accuracy: %.4f' % (accuracy))"
      ],
      "metadata": {
        "id": "TmGnAHMNbTfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhpGoEe-WkMQ"
      },
      "source": [
        "# Get ten and predict\n",
        "with torch.no_grad():\n",
        "    r = np.random.randint(0, len(mnist_test) - 1)\n",
        "    X_10_data = mnist_test.data[r:r + 10].view(-1, 28 * 28).float().to(device)\n",
        "    Y_10_data = mnist_test.targets[r:r + 10].to(device)\n",
        "\n",
        "    print('Label:      ', Y_10_data)\n",
        "    prediction = model(X_10_data)\n",
        "    print('Prediction: ', torch.argmax(prediction, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZuaW2hAUiX7"
      },
      "source": [
        "plt.imshow(mnist_test.data[r + 2].view(28, 28), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCl8mmi2z-SR"
      },
      "source": [
        "## With Batch Normailization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B451xuu_0CvJ"
      },
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 10\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsZykhDS3J2j"
      },
      "source": [
        "# nn layers\n",
        "linear1 = nn.Linear(784, 512, bias=True)\n",
        "linear2 = nn.Linear(512, 256, bias=True)\n",
        "linear3 = nn.Linear(256, 10, bias=True)\n",
        "bn1 = nn.BatchNorm1d(512)\n",
        "bn2 = nn.BatchNorm1d(256)\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# model\n",
        "bn_model = nn.Sequential(linear1, bn1, relu,\n",
        "                         linear2, bn2, relu,\n",
        "                         linear3).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "bn_optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfE1xUSi5Pch"
      },
      "source": [
        "bn_train_loss_list = []\n",
        "bn_train_acc_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    bn_model.train() # set the model to train mode (BatchNorm)\n",
        "    avg_loss = correct = 0\n",
        "\n",
        "    for X, Y in train_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        bn_optimizer.zero_grad()\n",
        "        Y_pred = bn_model.forward(X)\n",
        "        loss = criterion(Y_pred, Y)\n",
        "        loss.backward()\n",
        "        bn_optimizer.step()\n",
        "\n",
        "        avg_loss += loss / total_batch\n",
        "\n",
        "        correct_prediction = torch.argmax(Y_pred, 1) == Y\n",
        "        correct += correct_prediction.sum()\n",
        "\n",
        "    acc = (100*correct/len(train_loader.dataset))\n",
        "    bn_train_acc_list.append(acc.item())\n",
        "    bn_train_loss_list.append(avg_loss.item())\n",
        "    print(\"Epoch %2d: loss %.4f   accuracy %.2f\" % (epoch+1, avg_loss, acc))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFKUsRsF5cu9"
      },
      "source": [
        "# plot loss\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(1, epochs+1), train_loss_list, range(1, epochs+1), bn_train_loss_list)\n",
        "plt.legend(['Without BN', 'With BN'])\n",
        "plt.title('Training Loss')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(1, epochs+1),train_acc_list, range(1, epochs+1), bn_train_acc_list)\n",
        "plt.legend(['Without BN', 'With BN'])\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67uLaZLp55J_"
      },
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    bn_model.eval()   # set the model to evaluation mode (BatchNorm)\n",
        "    correct = 0\n",
        "    # Test the model using test sets\n",
        "    for X, Y in test_loader:\n",
        "        X_test = X.view(-1, 28 * 28).to(device)\n",
        "        Y_test = Y.to(device)\n",
        "\n",
        "        prediction = bn_model.forward(X_test)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "        correct += correct_prediction.sum()\n",
        "\n",
        "    accuracy = 100*correct/len(test_loader.dataset)\n",
        "    print('Test set Accuracy: %.4f' % (accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FVryLokW1J6"
      },
      "source": [
        "## With Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5XCo2ljW_7J"
      },
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 10\n",
        "batch_size = 100\n",
        "drop_prob = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCmvw5zwW33k"
      },
      "source": [
        "# nn layers\n",
        "linear1 = nn.Linear(784, 512, bias=True)\n",
        "linear2 = nn.Linear(512, 256, bias=True)\n",
        "linear3 = nn.Linear(256, 10, bias=True)\n",
        "\n",
        "relu = nn.ReLU()\n",
        "dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "# He initialization\n",
        "#nn.init.kaiming_normal_(linear1.weight, nonlinearity='relu')\n",
        "#nn.init.kaiming_normal_(linear2.weight, nonlinearity='relu')\n",
        "#nn.init.kaiming_normal_(linear3.weight, nonlinearity='relu')\n",
        "\n",
        "# model\n",
        "do_model = nn.Sequential(linear1, relu, dropout,\n",
        "                         linear2, relu, dropout,\n",
        "                         linear3).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "do_optimizer = torch.optim.Adam(do_model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpyRyY8Fy-dh"
      },
      "source": [
        "do_train_loss_list = []\n",
        "do_train_acc_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    do_model.train() # set the model to train mode (dropout=True)\n",
        "    avg_loss = correct = 0\n",
        "\n",
        "    for X, Y in train_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        do_optimizer.zero_grad()\n",
        "        Y_pred = do_model.forward(X)\n",
        "        loss = criterion(Y_pred, Y)\n",
        "        loss.backward()\n",
        "        do_optimizer.step()\n",
        "\n",
        "        avg_loss += loss / total_batch\n",
        "\n",
        "        correct_prediction = torch.argmax(Y_pred, 1) == Y\n",
        "        correct += correct_prediction.sum()\n",
        "\n",
        "    acc = (100*correct/len(train_loader.dataset))\n",
        "    do_train_acc_list.append(acc.item())\n",
        "    do_train_loss_list.append(avg_loss.item())\n",
        "    print(\"Epoch %2d: loss %.4f   accuracy %.2f\" % (epoch+1, avg_loss, acc))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-kdEqjjz2bL"
      },
      "source": [
        "# plot loss\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(1, epochs+1), train_loss_list, range(1, epochs+1), do_train_loss_list)\n",
        "plt.legend(['Without Dropout', 'With Dropout'])\n",
        "plt.title('Training Loss')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(1, epochs+1),train_acc_list, range(1, epochs+1), do_train_acc_list)\n",
        "plt.legend(['Without Dropout', 'With Dropout'])\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzv2iimxz84K"
      },
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    do_model.eval()   # set the model to evaluation mode (dropout=False)\n",
        "    correct = 0\n",
        "    # Test the model using test sets\n",
        "    for X, Y in test_loader:\n",
        "        X_test = X.view(-1, 28 * 28).to(device)\n",
        "        Y_test = Y.to(device)\n",
        "\n",
        "        prediction = do_model.forward(X_test)\n",
        "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "        correct += correct_prediction.sum()\n",
        "\n",
        "    accuracy = 100*correct/len(test_loader.dataset)\n",
        "    print('Test set Accuracy: %.4f' % (accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}